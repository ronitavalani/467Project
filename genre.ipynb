{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronitavalani/467Project/blob/main/genre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KTAw5tYOGafR"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "rXv3EGPsGdvw",
        "outputId": "bb494fbf-4c08-49f0-f5a7-01a060e95972"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_id</th>\n",
              "      <th>track_name</th>\n",
              "      <th>track_artist</th>\n",
              "      <th>track_popularity</th>\n",
              "      <th>track_album_id</th>\n",
              "      <th>track_album_name</th>\n",
              "      <th>track_album_release_date</th>\n",
              "      <th>playlist_name</th>\n",
              "      <th>playlist_id</th>\n",
              "      <th>playlist_genre</th>\n",
              "      <th>...</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>duration_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6f807x0ima9a1j3VPbc7VN</td>\n",
              "      <td>I Don't Care (with Justin Bieber) - Loud Luxur...</td>\n",
              "      <td>Ed Sheeran</td>\n",
              "      <td>66</td>\n",
              "      <td>2oCs0DGTsRO98Gh5ZSl2Cx</td>\n",
              "      <td>I Don't Care (with Justin Bieber) [Loud Luxury...</td>\n",
              "      <td>2019-06-14</td>\n",
              "      <td>Pop Remix</td>\n",
              "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
              "      <td>pop</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>-2.634</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0653</td>\n",
              "      <td>0.518</td>\n",
              "      <td>122.036</td>\n",
              "      <td>194754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0r7CVbZTWZgbTCYdfa2P31</td>\n",
              "      <td>Memories - Dillon Francis Remix</td>\n",
              "      <td>Maroon 5</td>\n",
              "      <td>67</td>\n",
              "      <td>63rPSO264uRjW1X5E6cWv6</td>\n",
              "      <td>Memories (Dillon Francis Remix)</td>\n",
              "      <td>2019-12-13</td>\n",
              "      <td>Pop Remix</td>\n",
              "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
              "      <td>pop</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>-4.969</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0373</td>\n",
              "      <td>0.0724</td>\n",
              "      <td>0.004210</td>\n",
              "      <td>0.3570</td>\n",
              "      <td>0.693</td>\n",
              "      <td>99.972</td>\n",
              "      <td>162600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1z1Hg7Vb0AhHDiEmnDE79l</td>\n",
              "      <td>All the Time - Don Diablo Remix</td>\n",
              "      <td>Zara Larsson</td>\n",
              "      <td>70</td>\n",
              "      <td>1HoSmj2eLcsrR0vE9gThr4</td>\n",
              "      <td>All the Time (Don Diablo Remix)</td>\n",
              "      <td>2019-07-05</td>\n",
              "      <td>Pop Remix</td>\n",
              "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
              "      <td>pop</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.432</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0794</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.1100</td>\n",
              "      <td>0.613</td>\n",
              "      <td>124.008</td>\n",
              "      <td>176616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>75FpbthrwQmzHlBJLuGdC7</td>\n",
              "      <td>Call You Mine - Keanu Silva Remix</td>\n",
              "      <td>The Chainsmokers</td>\n",
              "      <td>60</td>\n",
              "      <td>1nqYsOef1yKKuGOVchbsk6</td>\n",
              "      <td>Call You Mine - The Remixes</td>\n",
              "      <td>2019-07-19</td>\n",
              "      <td>Pop Remix</td>\n",
              "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
              "      <td>pop</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>-3.778</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1020</td>\n",
              "      <td>0.0287</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.2040</td>\n",
              "      <td>0.277</td>\n",
              "      <td>121.956</td>\n",
              "      <td>169093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1e8PAfcKUYoKkxPhrHqw4x</td>\n",
              "      <td>Someone You Loved - Future Humans Remix</td>\n",
              "      <td>Lewis Capaldi</td>\n",
              "      <td>69</td>\n",
              "      <td>7m7vv9wlQ4i0LFuJiE2zsQ</td>\n",
              "      <td>Someone You Loved (Future Humans Remix)</td>\n",
              "      <td>2019-03-05</td>\n",
              "      <td>Pop Remix</td>\n",
              "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
              "      <td>pop</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>-4.672</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0359</td>\n",
              "      <td>0.0803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0833</td>\n",
              "      <td>0.725</td>\n",
              "      <td>123.976</td>\n",
              "      <td>189052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 track_id                                         track_name  \\\n",
              "0  6f807x0ima9a1j3VPbc7VN  I Don't Care (with Justin Bieber) - Loud Luxur...   \n",
              "1  0r7CVbZTWZgbTCYdfa2P31                    Memories - Dillon Francis Remix   \n",
              "2  1z1Hg7Vb0AhHDiEmnDE79l                    All the Time - Don Diablo Remix   \n",
              "3  75FpbthrwQmzHlBJLuGdC7                  Call You Mine - Keanu Silva Remix   \n",
              "4  1e8PAfcKUYoKkxPhrHqw4x            Someone You Loved - Future Humans Remix   \n",
              "\n",
              "       track_artist  track_popularity          track_album_id  \\\n",
              "0        Ed Sheeran                66  2oCs0DGTsRO98Gh5ZSl2Cx   \n",
              "1          Maroon 5                67  63rPSO264uRjW1X5E6cWv6   \n",
              "2      Zara Larsson                70  1HoSmj2eLcsrR0vE9gThr4   \n",
              "3  The Chainsmokers                60  1nqYsOef1yKKuGOVchbsk6   \n",
              "4     Lewis Capaldi                69  7m7vv9wlQ4i0LFuJiE2zsQ   \n",
              "\n",
              "                                    track_album_name track_album_release_date  \\\n",
              "0  I Don't Care (with Justin Bieber) [Loud Luxury...               2019-06-14   \n",
              "1                    Memories (Dillon Francis Remix)               2019-12-13   \n",
              "2                    All the Time (Don Diablo Remix)               2019-07-05   \n",
              "3                        Call You Mine - The Remixes               2019-07-19   \n",
              "4            Someone You Loved (Future Humans Remix)               2019-03-05   \n",
              "\n",
              "  playlist_name             playlist_id playlist_genre  ... key  loudness  \\\n",
              "0     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   6    -2.634   \n",
              "1     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...  11    -4.969   \n",
              "2     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   1    -3.432   \n",
              "3     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   7    -3.778   \n",
              "4     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   1    -4.672   \n",
              "\n",
              "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
              "0     1       0.0583        0.1020          0.000000    0.0653    0.518   \n",
              "1     1       0.0373        0.0724          0.004210    0.3570    0.693   \n",
              "2     0       0.0742        0.0794          0.000023    0.1100    0.613   \n",
              "3     1       0.1020        0.0287          0.000009    0.2040    0.277   \n",
              "4     1       0.0359        0.0803          0.000000    0.0833    0.725   \n",
              "\n",
              "     tempo  duration_ms  \n",
              "0  122.036       194754  \n",
              "1   99.972       162600  \n",
              "2  124.008       176616  \n",
              "3  121.956       169093  \n",
              "4  123.976       189052  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load in the data set\n",
        "df = pd.read_csv(\n",
        "    \"spotify_songs.csv\"\n",
        ")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KDFHLn_AGkuG"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "\n",
        "\n",
        "# Mixed Genre Problem\n",
        "\n",
        "# Attempt 1: Specify different types of genres instead of pop - indicates that pop is why the model is performing well\n",
        "# def get_preferred_genre(genre_str):\n",
        "#     genres = genre_str.split(\",\")\n",
        "#     genres = [g.strip() for g in genres if g.strip()]  # clean and remove empty entries\n",
        "#     if not genres:\n",
        "#         return \"Unknown\"\n",
        "#     if genres[0].lower() == \"pop\" and len(genres) > 1:\n",
        "#         return genres[1]\n",
        "#     return genres[0]\n",
        "\n",
        "# Attempt 2: Create a separate \"mixed\" genre for multiple genre songs\n",
        "# def get_preferred_genre(genre_str):\n",
        "#     genres = genre_str.split(\",\")\n",
        "#     genres = [g.strip() for g in genres if g.strip()]  # clean and remove empty entries\n",
        "#     if len(genres) > 1:\n",
        "#         return \"Mixed\"\n",
        "#     return genres[0] if genres else \"Unknown\"\n",
        "\n",
        "# df['genre'] = df['genre'].astype(str).apply(get_preferred_genre)\n",
        "\n",
        "# Keep only the first genre when a song is classified with multiple\n",
        "df['playlist_genre'] = df['playlist_genre'].astype(str).apply(lambda x: x.split(',')[0].strip())\n",
        "\n",
        "\n",
        "# Drop qualitative data (song name, artist name)\n",
        "non_numeric_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "non_numeric_cols.remove('playlist_genre')\n",
        "df = df.drop(columns=non_numeric_cols)\n",
        "\n",
        "# Drop empty values\n",
        "df = df.dropna()\n",
        "\n",
        "# Create input and output\n",
        "X = df.drop(columns=['playlist_genre'])\n",
        "y = df['playlist_genre']\n",
        "\n",
        "# Underrepresented Data Problem\n",
        "# Drop genre classes with only 1 example\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "value_counts = pd.Series(y_encoded).value_counts()\n",
        "valid_classes = value_counts[value_counts > 1].index\n",
        "valid_mask = pd.Series(y_encoded).isin(valid_classes)\n",
        "X = X[valid_mask]\n",
        "y = y[valid_mask].reset_index(drop=True)\n",
        "\n",
        "# Redo output labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KsprkPL6GpdI"
      },
      "outputs": [],
      "source": [
        "# Prepare data for training\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Create a PyTorch data set\n",
        "class SongDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.X = torch.tensor(features, dtype=torch.float32)\n",
        "        self.y = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = SongDataset(X_train, y_train)\n",
        "test_dataset = SongDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3eL5cgX5Gruf"
      },
      "outputs": [],
      "source": [
        "# Define neural network\n",
        "# Simple model with one hidden layer and\n",
        "class GenreNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GenreNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Deeper model with 2 hidden layers and dropout - performs worse\n",
        "class GenreNet2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GenreNet2, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.fc1(x))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "# Model, loss, optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = len(np.unique(y_encoded))\n",
        "\n",
        "model = GenreNet(input_dim, hidden_dim, output_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW__tuiiGtkP",
        "outputId": "8a9400f8-367c-437a-fc83-dd76c6063eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/16, Loss: 1.4245\n",
            "Epoch 2/16, Loss: 1.3118\n",
            "Epoch 3/16, Loss: 1.2784\n",
            "Epoch 4/16, Loss: 1.2606\n",
            "Epoch 5/16, Loss: 1.2508\n",
            "Epoch 6/16, Loss: 1.2436\n",
            "Epoch 7/16, Loss: 1.2380\n",
            "Epoch 8/16, Loss: 1.2335\n",
            "Epoch 9/16, Loss: 1.2295\n",
            "Epoch 10/16, Loss: 1.2266\n",
            "Epoch 11/16, Loss: 1.2236\n",
            "Epoch 12/16, Loss: 1.2202\n",
            "Epoch 13/16, Loss: 1.2184\n",
            "Epoch 14/16, Loss: 1.2165\n",
            "Epoch 15/16, Loss: 1.2147\n",
            "Epoch 16/16, Loss: 1.2129\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "epochs = 16\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MufPDFc1LCJ",
        "outputId": "54d56142-1771-4d5f-84fe-0d6c78d5c652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Accuracy: 52.64%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "# Consistently gaining around 67% classification accuracy - solid start but not good\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "print(f\"\\nTest Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "32Ga4uxvab26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%%script` not found.\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter Experimentation\n",
        "%%script true\n",
        "print(\"Experimentation\")\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "epoch_range = list(range(1, 50))  # Try from 1 to 50 epochs\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Convert test set to tensors\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "for num_epochs in epoch_range:\n",
        "    # Re-initialize model for a fresh start each run\n",
        "    model = GenreNet(input_dim, hidden_dim, output_dim)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train model for current epoch count\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    # Store final training loss for this run\n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "    # Evaluate test accuracy\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_test_tensor)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        accuracy = (predictions == y_test_tensor).float().mean().item()\n",
        "        test_accuracies.append(accuracy)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(epoch_range, train_losses, label=\"Training Loss\", color=\"blue\")\n",
        "plt.plot(epoch_range, test_accuracies, label=\"Test Accuracy\", color=\"green\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss / Accuracy\")\n",
        "plt.title(\"Training Loss vs. Test Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"\\nMax Test Accuracy: {max(test_accuracies)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbIbyRuR701N",
        "outputId": "e61fb701-81eb-462a-dcba-4bcc85b0b801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted 'pop' in test set: 859 out of 6567 samples (13.08%)\n",
            "'Pop' samples in training set: 4405 out of 26266 (16.77%)\n",
            "\n",
            "Total Misclassified: 3110\n",
            "Index 0: True Label = rock, Predicted = rap\n",
            "Index 1: True Label = edm, Predicted = rap\n",
            "Index 2: True Label = latin, Predicted = pop\n",
            "Index 6: True Label = r&b, Predicted = edm\n",
            "Index 8: True Label = pop, Predicted = latin\n",
            "Index 9: True Label = latin, Predicted = rock\n",
            "Index 10: True Label = r&b, Predicted = pop\n",
            "Index 19: True Label = pop, Predicted = rock\n",
            "Index 20: True Label = edm, Predicted = pop\n",
            "Index 22: True Label = pop, Predicted = r&b\n",
            "\n",
            "ðŸ“‰ Misclassification Rates by Genre (% of genre misclassified):\n",
            "edm: 403/1209 misclassified (33.3%)\n",
            "latin: 631/1031 misclassified (61.2%)\n",
            "pop: 772/1102 misclassified (70.1%)\n",
            "r&b: 588/1086 misclassified (54.1%)\n",
            "rap: 443/1149 misclassified (38.6%)\n",
            "rock: 273/990 misclassified (27.6%)\n",
            "\n",
            "ðŸ“Š Original Genre Distribution (after preprocessing):\n",
            "edm: 6043\n",
            "rap: 5746\n",
            "pop: 5507\n",
            "r&b: 5431\n",
            "latin: 5155\n",
            "rock: 4951\n"
          ]
        }
      ],
      "source": [
        "# Error Analysis\n",
        "# % of Pop Songs vs. Pop Songs Predicted\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "predicted_genres = le.inverse_transform(all_preds)\n",
        "\n",
        "pop_count = sum(1 for genre in predicted_genres if genre.lower() == 'pop')\n",
        "total = len(predicted_genres)\n",
        "\n",
        "print(f\"\\nPredicted 'pop' in test set: {pop_count} out of {total} samples ({pop_count/total:.2%})\")\n",
        "\n",
        "\n",
        "y_train_genres = le.inverse_transform(y_train)\n",
        "\n",
        "num_pop_train = sum(1 for genre in y_train_genres if genre.lower() == \"pop\")\n",
        "total_samples = len(y_train)\n",
        "\n",
        "print(f\"'Pop' samples in training set: {num_pop_train} out of {total_samples} \"\n",
        "      f\"({(num_pop_train / total_samples) * 100:.2f}%)\")\n",
        "\n",
        "# Analyze incorrect classifications\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "# Store misclassified indices\n",
        "misclassified = []\n",
        "# No need for gradient tracking during evaluation\n",
        "with torch.no_grad():\n",
        "    for i, (X_batch, y_batch) in enumerate(test_loader):  # Assuming you have a test_loader\n",
        "        outputs = model(X_batch)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        # Find where prediction != actual\n",
        "        incorrect = predictions != y_batch\n",
        "\n",
        "        # Store indices or values of misclassified samples\n",
        "        for j in range(X_batch.size(0)):\n",
        "            if incorrect[j]:\n",
        "                misclassified.append({\n",
        "                    \"index\": i * test_loader.batch_size + j,\n",
        "                    \"true\": y_batch[j].item(),\n",
        "                    \"pred\": predictions[j].item()\n",
        "                })\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nTotal Misclassified: {len(misclassified)}\")\n",
        "for sample in misclassified[:10]:  # Show first 10\n",
        "    true_label = le.inverse_transform([sample['true']])[0]\n",
        "    pred_label = le.inverse_transform([sample['pred']])[0]\n",
        "    print(f\"Index {sample['index']}: True Label = {true_label}, Predicted = {pred_label}\")\n",
        "\n",
        "\n",
        "# Misclassifications by output\n",
        "from collections import Counter, defaultdict\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "all_true_labels = le.inverse_transform(y_test_tensor.numpy())\n",
        "\n",
        "total_per_genre = Counter(all_true_labels)\n",
        "\n",
        "misclassified_counts = defaultdict(int)\n",
        "\n",
        "for sample in misclassified:\n",
        "    genre = le.inverse_transform([sample['true']])[0]\n",
        "    misclassified_counts[genre] += 1\n",
        "\n",
        "print(\"\\nðŸ“‰ Misclassification Rates by Genre (% of genre misclassified):\")\n",
        "for genre in sorted(total_per_genre.keys()):\n",
        "    total = total_per_genre[genre]\n",
        "    wrong = misclassified_counts[genre]\n",
        "    percent = 100 * wrong / total\n",
        "    print(f\"{genre}: {wrong}/{total} misclassified ({percent:.1f}%)\")\n",
        "\n",
        "\n",
        "\n",
        "# Print sample distribution\n",
        "genre_labels = le.inverse_transform(y_encoded)\n",
        "\n",
        "from collections import Counter\n",
        "original_distribution = Counter(genre_labels)\n",
        "\n",
        "print(\"\\nðŸ“Š Original Genre Distribution (after preprocessing):\")\n",
        "for genre, count in original_distribution.most_common():\n",
        "    print(f\"{genre}: {count}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
